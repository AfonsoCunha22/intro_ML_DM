{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit options (optional)\n",
    "# pd.set_option(\"display.max_columns\", None)\n",
    "# pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Functions ==\n",
    "\n",
    "# - Plotting\n",
    "\n",
    "def plot_correlation_heatmap(data: pd.DataFrame, columns: list):\n",
    "    \"\"\"\n",
    "    Plot correlation heatmap of specific columns\n",
    "    \"\"\"\n",
    "    correlation_matrix = data[columns].corr()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", linewidth=0.5)\n",
    "    plt.title(\"Correlation Heatmap for selected attributes\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_distributions(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Plot distributions of numeric data\n",
    "    \"\"\"\n",
    "    sns.set_style(\"whitegrid\", {\"grid_linestyle\": \"--\"})\n",
    "    # For each column plot their distribution\n",
    "    # I need a max column grid\n",
    "    columns = data.columns\n",
    "    num_plots = len(columns)\n",
    "    num_rows = math.ceil( num_plots / 2)\n",
    "    num_columns = 2\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "    for i, column in enumerate(columns):\n",
    "        sns.histplot(data[column], ax=axes[i], kde=True)\n",
    "        axes[i].set_title(f'Distribution of {column}')\n",
    "        axes[i].set_xlabel(column)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_violin(data: pd.DataFrame, column: str):\n",
    "    \"\"\"\n",
    "    Plot violin \n",
    "    \"\"\"    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.violinplot(y=column, data=data, orient=\"v\")\n",
    "    plt.title(f\"Violin Plot of {column}\")\n",
    "    plt.show()\n",
    "\n",
    "# - PCA Analysis\n",
    "\n",
    "def plot_PCA_variance(numbers: list, ratios: list):\n",
    "    \"\"\"\n",
    "    Plot variance ratio\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(4,2), dpi=150)\n",
    "    plt.grid()\n",
    "    plt.plot(numbers, ratios, marker=\"o\")\n",
    "    plt.xlabel(\"n_components\")\n",
    "    plt.ylabel(\"Explained Variance Ratio\")\n",
    "    plt.title(\"n_components vs. Explained Variance Ratio\")\n",
    "    plt.show()\n",
    "\n",
    "# ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset/dataset-spotify-2023.csv\"\n",
    "data = pd.read_csv(dataset_path, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rename selected columns\n",
    "columns = [\"danceability_%\", \"valence_%\", \"energy_%\", \"acousticness_%\", \"instrumentalness_%\",\n",
    "\"liveness_%\", \"speechiness_%\"]\n",
    "data = data.rename(columns={column: column.replace(\"_%\", \"\") for column in columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print nan count of `key` (95), no other column has missing data\n",
    "key_None_count = data[\"key\"].isna().sum()\n",
    "in_shazam_charts_None_count = data[\"in_shazam_charts\"].isna().sum()\n",
    "\n",
    "print(\"`key` None count: \", key_None_count)\n",
    "print(\"`in_shazam_charts` None count: \", in_shazam_charts_None_count)\n",
    "\n",
    "# Replace NaN values with Unspecified, it may be useful later on\n",
    "data = data.replace(np.nan, \"Unavailable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is malformed, need to remove comma `,`\n",
    "data[\"in_deezer_playlists\"] = data[\"in_deezer_playlists\"].replace(\",\", \"\", regex=True)\n",
    "data[\"in_shazam_charts\"] = data[\"in_deezer_playlists\"].replace(\",\", \"\", regex=True)\n",
    "\n",
    "# Convert columns to int64\n",
    "# streams, in_deezer_playlists, in_shazam_charts\n",
    "data[\"in_deezer_playlists\"] = data[\"in_deezer_playlists\"].astype(int)\n",
    "data[\"in_shazam_charts\"] = data[\"in_shazam_charts\"].astype(int)\n",
    "\n",
    "# Streams overflowed with int, so use np.int64 to fit the whole numbers\n",
    "data[\"streams\"] = data[\"streams\"].astype(np.int64)\n",
    "\n",
    "# Wee see that `streams` is very large compared to to other data, next larger is `in_spotify_playlists`\n",
    "# Add extra column with log value of streams\n",
    "data[\"streams_log\"] = np.log2(data[\"streams\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problematic record 576 removed manually\n",
    "# Love Grows (Where My Rosemary Goes),Edison Lighthouse,1,1970,1,1,2877,0,,16,0,54,0,0,110,A,Major,53,75,69,7,0,17,3\n",
    "\n",
    "# Print statistics, print them without the scientific notation\n",
    "print(\"Statistics\", data.describe().apply(lambda s: s.apply(lambda x: format(x, \"g\"))).transpose())\n",
    "\n",
    "# Print unique values of mode\n",
    "# print(data[\"mode\"].value_counts())\n",
    "# print(\"Index of mistake in data:\", data.index[data[\"mode\"] == \"53\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding values\n",
    "data = pd.get_dummies(data, columns=[\"key\", \"mode\"], prefix=[\"key\", \"mode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns\n",
    "data_numeric = data.select_dtypes(exclude=\"object\")\n",
    "data_numeric.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of numeric datas\n",
    "plot_distributions(data=data_numeric.iloc[:, 12:17])\n",
    "plot_distributions(data=data_numeric.iloc[:, [4, 5, 7, 8, 9, 10, 11]])\n",
    "plot_distributions(data=data_numeric.iloc[:, [0, 1, 2, 3, 18]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "plot_correlation_heatmap(data=data, columns = [\"danceability\", \"valence\", \"energy\", \"acousticness\", \"instrumentalness\",\n",
    "\"liveness\", \"speechiness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Analysis\n",
    "# Number of PCA's and variance captured\n",
    "data_scaled = StandardScaler().fit_transform(data_numeric)\n",
    "variance_ratios = []\n",
    "numbers = range(0, len(data_numeric.columns), 5)\n",
    "for number in numbers:\n",
    "    pca = PCA(n_components=number)\n",
    "    pca.fit_transform(data_scaled)\n",
    "    variance_ratios.append(np.sum(pca.explained_variance_ratio_))\n",
    "    print(f\"Number of components: {number}, total variance {sum(pca.explained_variance_ratio_)}\")\n",
    "\n",
    "plot_PCA_variance(numbers=numbers, ratios=variance_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characterizing data columns\n",
    "\n",
    "* track_name    (discrete, nominal) \n",
    "* artist(s)_name    (discrete, nominal) \n",
    "* artist_count  (discrete, ratio) \n",
    "* released_year (discrete, ordinal) \n",
    "* released_month    (discrete, ordinal) \n",
    "* released_day  (discrete, ordinal) \n",
    "* in_spotify_playlists  (discrete, ratio) \n",
    "* in_spotify_charts (discrete, ratio) \n",
    "* streams   (discrete, ratio) \n",
    "* in_apple_playlists    (discrete, ratio)\n",
    "* in_apple_charts   (discrete, ratio) \n",
    "* in_deezer_playlists   (discrete, ratio) \n",
    "* in_deezer_charts  (discrete, ratio)\n",
    "* in_shazam_charts  (discrete, ratio) \n",
    "* bpm   (continuous, ratio) \n",
    "* key   (discrete, nominal) \n",
    "* mode  (discrete, nominal) \n",
    "* danceability_%    (continuous, ratio) \n",
    "* valence_% (continuous, ratio) \n",
    "* energy_%  (continuous, ratio) \n",
    "* acousticness_%    (continuous, ratio) \n",
    "* instrumentalness_%    (continuous, ratio) \n",
    "* liveness_%    (continuous, ratio) \n",
    "* speechiness_% (continuous, ratio) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful code from Toolbox\n",
    "\n",
    "There is a list of already implemented functions we can use from the ToolBox to perform Data Analysis.\n",
    "\n",
    "* categoric2numeric.py : one-hot encoding\n",
    "* similarity.py : similarity matrices\n",
    "* statistics.py : chi-squared tests and other\n",
    "* ex1_5_4.py : regression problem plot\n",
    "* ex2_1_2.py : scatterplot\n",
    "* ex2_1_3.py : PCAs\n",
    "* ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlshit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
